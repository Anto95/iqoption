{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005263d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from conf import download_conf\n",
    "from utils.paths import tp\n",
    "\n",
    "tickers = download_conf.tickers\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a50fb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded 0 / 835.\n",
      "INFO:__main__:Loaded 10 / 835.\n",
      "INFO:__main__:Loaded 20 / 835.\n",
      "INFO:__main__:Loaded 30 / 835.\n",
      "INFO:__main__:Loaded 40 / 835.\n",
      "INFO:__main__:Loaded 50 / 835.\n",
      "INFO:__main__:Loaded 60 / 835.\n",
      "INFO:__main__:Loaded 70 / 835.\n",
      "INFO:__main__:Loaded 80 / 835.\n",
      "INFO:__main__:Loaded 90 / 835.\n",
      "INFO:__main__:Loaded 100 / 835.\n",
      "INFO:__main__:Loaded 110 / 835.\n",
      "INFO:__main__:Loaded 120 / 835.\n",
      "INFO:__main__:Loaded 130 / 835.\n",
      "INFO:__main__:Loaded 140 / 835.\n",
      "INFO:__main__:Loaded 150 / 835.\n",
      "INFO:__main__:Loaded 160 / 835.\n",
      "INFO:__main__:Loaded 170 / 835.\n",
      "INFO:__main__:Loaded 180 / 835.\n",
      "INFO:__main__:Loaded 190 / 835.\n",
      "INFO:__main__:Loaded 200 / 835.\n",
      "INFO:__main__:Loaded 210 / 835.\n",
      "INFO:__main__:Loaded 220 / 835.\n",
      "INFO:__main__:Loaded 230 / 835.\n",
      "INFO:__main__:Loaded 240 / 835.\n",
      "INFO:__main__:Loaded 250 / 835.\n",
      "INFO:__main__:Loaded 260 / 835.\n",
      "INFO:__main__:Loaded 270 / 835.\n",
      "INFO:__main__:Loaded 280 / 835.\n",
      "INFO:__main__:Loaded 290 / 835.\n",
      "INFO:__main__:Loaded 300 / 835.\n",
      "INFO:__main__:Loaded 310 / 835.\n",
      "INFO:__main__:Loaded 320 / 835.\n",
      "INFO:__main__:Loaded 330 / 835.\n",
      "INFO:__main__:Loaded 340 / 835.\n",
      "INFO:__main__:Loaded 350 / 835.\n",
      "INFO:__main__:Loaded 360 / 835.\n",
      "INFO:__main__:Loaded 370 / 835.\n",
      "INFO:__main__:Loaded 380 / 835.\n",
      "INFO:__main__:Loaded 390 / 835.\n",
      "INFO:__main__:Loaded 400 / 835.\n",
      "INFO:__main__:Loaded 410 / 835.\n",
      "INFO:__main__:Loaded 420 / 835.\n",
      "INFO:__main__:Loaded 430 / 835.\n",
      "INFO:__main__:Loaded 440 / 835.\n",
      "INFO:__main__:Loaded 450 / 835.\n",
      "INFO:__main__:Loaded 460 / 835.\n",
      "INFO:__main__:Loaded 470 / 835.\n",
      "INFO:__main__:Loaded 480 / 835.\n",
      "INFO:__main__:Loaded 490 / 835.\n",
      "INFO:__main__:Loaded 500 / 835.\n",
      "INFO:__main__:Loaded 510 / 835.\n",
      "INFO:__main__:Loaded 520 / 835.\n",
      "INFO:__main__:Loaded 530 / 835.\n",
      "INFO:__main__:Loaded 540 / 835.\n",
      "INFO:__main__:Loaded 550 / 835.\n",
      "INFO:__main__:Loaded 560 / 835.\n",
      "INFO:__main__:Loaded 570 / 835.\n",
      "INFO:__main__:Loaded 580 / 835.\n",
      "INFO:__main__:Loaded 590 / 835.\n",
      "INFO:__main__:Loaded 600 / 835.\n",
      "INFO:__main__:Loaded 610 / 835.\n",
      "INFO:__main__:Loaded 620 / 835.\n",
      "INFO:__main__:Loaded 630 / 835.\n",
      "INFO:__main__:Loaded 640 / 835.\n",
      "INFO:__main__:Loaded 650 / 835.\n",
      "INFO:__main__:Loaded 660 / 835.\n",
      "INFO:__main__:Loaded 670 / 835.\n",
      "INFO:__main__:Loaded 680 / 835.\n",
      "INFO:__main__:Loaded 690 / 835.\n",
      "INFO:__main__:Loaded 700 / 835.\n",
      "INFO:__main__:Loaded 710 / 835.\n",
      "INFO:__main__:Loaded 720 / 835.\n",
      "INFO:__main__:Loaded 730 / 835.\n",
      "INFO:__main__:Loaded 740 / 835.\n",
      "INFO:__main__:Loaded 750 / 835.\n",
      "INFO:__main__:Loaded 760 / 835.\n",
      "INFO:__main__:Loaded 770 / 835.\n",
      "INFO:__main__:Loaded 780 / 835.\n",
      "INFO:__main__:Loaded 790 / 835.\n",
      "INFO:__main__:Loaded 800 / 835.\n",
      "INFO:__main__:Loaded 810 / 835.\n",
      "INFO:__main__:Loaded 820 / 835.\n",
      "INFO:__main__:Loaded 830 / 835.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock_splits</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-17 00:00:00</td>\n",
       "      <td>11.13</td>\n",
       "      <td>12.3900</td>\n",
       "      <td>10.74</td>\n",
       "      <td>11.0900</td>\n",
       "      <td>11.0900</td>\n",
       "      <td>1286600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-18 00:00:00</td>\n",
       "      <td>11.03</td>\n",
       "      <td>11.4500</td>\n",
       "      <td>10.80</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>165800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-22 00:00:00</td>\n",
       "      <td>11.40</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>11.30</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>50200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-23 00:00:00</td>\n",
       "      <td>11.55</td>\n",
       "      <td>11.5500</td>\n",
       "      <td>11.04</td>\n",
       "      <td>11.3100</td>\n",
       "      <td>11.3100</td>\n",
       "      <td>26300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-24 00:00:00</td>\n",
       "      <td>11.22</td>\n",
       "      <td>11.2800</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>20900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BWAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>2023-02-13 00:00:00</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.3199</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.3193</td>\n",
       "      <td>1.3193</td>\n",
       "      <td>274673.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>2023-02-14 00:00:00</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>137757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>2023-02-15 00:00:00</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.3300</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.3250</td>\n",
       "      <td>1.3250</td>\n",
       "      <td>62003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2023-02-16 00:00:00</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.3202</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>216836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2023-02-17 00:00:00</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>112912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CTRM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834555 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date   open     high    low    close  adj_close  \\\n",
       "0     2019-04-17 00:00:00  11.13  12.3900  10.74  11.0900    11.0900   \n",
       "1     2019-04-18 00:00:00  11.03  11.4500  10.80  11.2500    11.2500   \n",
       "2     2019-04-22 00:00:00  11.40  11.5000  11.30  11.5000    11.5000   \n",
       "3     2019-04-23 00:00:00  11.55  11.5500  11.04  11.3100    11.3100   \n",
       "4     2019-04-24 00:00:00  11.22  11.2800  11.00  11.2500    11.2500   \n",
       "...                   ...    ...      ...    ...      ...        ...   \n",
       "1009  2023-02-13 00:00:00   1.28   1.3199   1.26   1.3193     1.3193   \n",
       "1010  2023-02-14 00:00:00   1.28   1.3200   1.28   1.3200     1.3200   \n",
       "1011  2023-02-15 00:00:00   1.32   1.3300   1.31   1.3250     1.3250   \n",
       "1012  2023-02-16 00:00:00   1.31   1.3202   1.29   1.2950     1.2950   \n",
       "1013  2023-02-17 00:00:00   1.28   1.3000   1.27   1.2850     1.2850   \n",
       "\n",
       "         volume  dividends  stock_splits ticker  \n",
       "0     1286600.0        0.0           0.0   BWAY  \n",
       "1      165800.0        0.0           0.0   BWAY  \n",
       "2       50200.0        0.0           0.0   BWAY  \n",
       "3       26300.0        0.0           0.0   BWAY  \n",
       "4       20900.0        0.0           0.0   BWAY  \n",
       "...         ...        ...           ...    ...  \n",
       "1009   274673.0        0.0           0.0   CTRM  \n",
       "1010   137757.0        0.0           0.0   CTRM  \n",
       "1011    62003.0        0.0           0.0   CTRM  \n",
       "1012   216836.0        0.0           0.0   CTRM  \n",
       "1013   112912.0        0.0           0.0   CTRM  \n",
       "\n",
       "[2834555 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for i, ticker in enumerate(tickers):\n",
    "    if i % 10 == 0:\n",
    "        logger.info(f\"Loaded {i} / {len(tickers)}.\")\n",
    "    path = tp(ticker, granularity=\"1d\")\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"ticker\"] = ticker\n",
    "    dfs.append(df)\n",
    "df_raw = pd.concat(dfs)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33091ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:205 were there since 2000.\n",
      "INFO:__main__:150 were there since 2000 and had more than 50K transactions per day in average.\n",
      "INFO:__main__:149 were there since 2000 and had more than 50K transactions per day in average and hadn't any none.\n",
      "INFO:__main__:130 were there since 2000 and had more than 50K transactions per day in average and hadn't any none and didn't do more than x20.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock_splits</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>24.5000</td>\n",
       "      <td>24.7500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>12950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>22.5000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>22.5000</td>\n",
       "      <td>22.5000</td>\n",
       "      <td>6275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>22.2500</td>\n",
       "      <td>22.2500</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>3575.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>20.5000</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>7725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.9200</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.9100</td>\n",
       "      <td>2.9100</td>\n",
       "      <td>14709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>2.8550</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.8550</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>2.9253</td>\n",
       "      <td>2.9253</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>2.9713</td>\n",
       "      <td>2.9900</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>7670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9690</th>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>2.9709</td>\n",
       "      <td>3.0600</td>\n",
       "      <td>2.9400</td>\n",
       "      <td>3.0400</td>\n",
       "      <td>3.0400</td>\n",
       "      <td>19102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756600 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     open     high      low    close  adj_close   volume  \\\n",
       "524  2000-01-03  24.5000  24.7500  21.5000  22.0000    22.0000  12950.0   \n",
       "525  2000-01-04  22.5000  23.0000  21.5000  22.5000    22.5000   6275.0   \n",
       "526  2000-01-05  22.2500  22.2500  22.0000  22.0000    22.0000   3575.0   \n",
       "527  2000-01-06  21.5000  22.0000  20.5000  21.5000    21.5000   2675.0   \n",
       "528  2000-01-07  22.0000  22.0000  20.2500  21.5000    21.5000   7725.0   \n",
       "...         ...      ...      ...      ...      ...        ...      ...   \n",
       "9686 2023-02-13   2.8800   2.9200   2.8800   2.9100     2.9100  14709.0   \n",
       "9687 2023-02-14   2.8550   2.8800   2.8550   2.8800     2.8800   1278.0   \n",
       "9688 2023-02-15   2.9253   2.9253   2.9000   2.9000     2.9000   1064.0   \n",
       "9689 2023-02-16   2.9713   2.9900   2.9401   2.9401     2.9401   7670.0   \n",
       "9690 2023-02-17   2.9709   3.0600   2.9400   3.0400     3.0400  19102.0   \n",
       "\n",
       "      dividends  stock_splits ticker  \n",
       "524         0.0           0.0   ASRT  \n",
       "525         0.0           0.0   ASRT  \n",
       "526         0.0           0.0   ASRT  \n",
       "527         0.0           0.0   ASRT  \n",
       "528         0.0           0.0   ASRT  \n",
       "...         ...           ...    ...  \n",
       "9686        0.0           0.0   BMRA  \n",
       "9687        0.0           0.0   BMRA  \n",
       "9688        0.0           0.0   BMRA  \n",
       "9689        0.0           0.0   BMRA  \n",
       "9690        0.0           0.0   BMRA  \n",
       "\n",
       "[756600 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "start_date = datetime.datetime(2000, 1, 1, 0, 0, 0)\n",
    "df = df_raw\n",
    "df.date = df_raw.date.astype(np.datetime64)\n",
    "df_tickers = df_raw.groupby(\"ticker\")[\"date\"].agg([min, max]).reset_index()\n",
    "df_tickers = df_tickers[(df_tickers[\"min\"] <= start_date) & (df_tickers[\"max\"] >= datetime.datetime.now() - datetime.timedelta(days=4))][[\"ticker\"]]\n",
    "tickers = df_tickers.ticker.values\n",
    "logger.info(f\"{tickers.shape[0]} were there since 2000.\")\n",
    "df_tickers = df_raw.groupby(\"ticker\")[\"volume\"].agg(\"mean\").reset_index()\n",
    "df_tickers = df_tickers[df_tickers.volume < 50000]\n",
    "tickers = np.array(list(set(list(tickers)) - set(list(df_tickers.ticker.values))))\n",
    "logger.info(f\"{tickers.shape[0]} were there since 2000 and had more than 50K transactions per day in average.\")\n",
    "df_tickers = df_raw.groupby('ticker')[\"open\"].apply(lambda x: any(x.isna())).reset_index()\n",
    "df_tickers = df_tickers[df_tickers.open]\n",
    "tickers = np.array(list(set(list(tickers)) - set(list(df_tickers.ticker.values))))\n",
    "logger.info(f\"{tickers.shape[0]} were there since 2000 and had more than 50K transactions per day in average and hadn't any none.\")\n",
    "df_tickers = pd.DataFrame(tickers, columns = [\"ticker\"])\n",
    "df = df.join(df_tickers.set_index(\"ticker\"), how = \"inner\", on = \"ticker\")\n",
    "df_norm = df_raw.groupby('ticker')[\"open\"].apply(lambda x: ((x.values[1:] + 1) / (x.values[:-1] + 1)).max() < 5).reset_index()\n",
    "tickers = df_norm[df_norm.open].ticker.values\n",
    "df_tickers = pd.DataFrame(tickers, columns = [\"ticker\"])\n",
    "df = df.join(df_tickers.set_index(\"ticker\"), how = \"inner\", on = \"ticker\")\n",
    "logger.info(f\"{df.groupby('ticker').size().reset_index().shape[0]} were there since 2000 and had more than 50K transactions per day in average and hadn't any none and didn't do more than x20.\")\n",
    "df = df[df.date >= start_date]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2b56be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock_splits</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2.1900</td>\n",
       "      <td>2.7300</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>3146900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>2.7200</td>\n",
       "      <td>2.4700</td>\n",
       "      <td>2.6100</td>\n",
       "      <td>2.6100</td>\n",
       "      <td>1286400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>2.6200</td>\n",
       "      <td>2.3600</td>\n",
       "      <td>2.4500</td>\n",
       "      <td>2.4500</td>\n",
       "      <td>943700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2.4600</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>2.3700</td>\n",
       "      <td>2.4100</td>\n",
       "      <td>2.4100</td>\n",
       "      <td>565000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>2.4400</td>\n",
       "      <td>2.8200</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>2.7100</td>\n",
       "      <td>2.7100</td>\n",
       "      <td>2168900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.9200</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.9100</td>\n",
       "      <td>2.9100</td>\n",
       "      <td>14709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>2.8550</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.8550</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>2.8800</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>2.9253</td>\n",
       "      <td>2.9253</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>2.9713</td>\n",
       "      <td>2.9900</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>7670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9690</th>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>2.9709</td>\n",
       "      <td>3.0600</td>\n",
       "      <td>2.9400</td>\n",
       "      <td>3.0400</td>\n",
       "      <td>3.0400</td>\n",
       "      <td>19102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36920 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    open    high     low   close  adj_close     volume  \\\n",
       "6060 2022-01-03  2.1900  2.7300  2.1800  2.6500     2.6500  3146900.0   \n",
       "6061 2022-01-04  2.6500  2.7200  2.4700  2.6100     2.6100  1286400.0   \n",
       "6062 2022-01-05  2.6000  2.6200  2.3600  2.4500     2.4500   943700.0   \n",
       "6063 2022-01-06  2.4600  2.5800  2.3700  2.4100     2.4100   565000.0   \n",
       "6064 2022-01-07  2.4400  2.8200  2.4200  2.7100     2.7100  2168900.0   \n",
       "...         ...     ...     ...     ...     ...        ...        ...   \n",
       "9686 2023-02-13  2.8800  2.9200  2.8800  2.9100     2.9100    14709.0   \n",
       "9687 2023-02-14  2.8550  2.8800  2.8550  2.8800     2.8800     1278.0   \n",
       "9688 2023-02-15  2.9253  2.9253  2.9000  2.9000     2.9000     1064.0   \n",
       "9689 2023-02-16  2.9713  2.9900  2.9401  2.9401     2.9401     7670.0   \n",
       "9690 2023-02-17  2.9709  3.0600  2.9400  3.0400     3.0400    19102.0   \n",
       "\n",
       "      dividends  stock_splits ticker  \n",
       "6060        0.0           0.0   ASRT  \n",
       "6061        0.0           0.0   ASRT  \n",
       "6062        0.0           0.0   ASRT  \n",
       "6063        0.0           0.0   ASRT  \n",
       "6064        0.0           0.0   ASRT  \n",
       "...         ...           ...    ...  \n",
       "9686        0.0           0.0   BMRA  \n",
       "9687        0.0           0.0   BMRA  \n",
       "9688        0.0           0.0   BMRA  \n",
       "9689        0.0           0.0   BMRA  \n",
       "9690        0.0           0.0   BMRA  \n",
       "\n",
       "[36920 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_date = \"2022-01-01\"\n",
    "df_train = df[df.date <= train_date]\n",
    "df_test = df[df.date > train_date]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91da3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\"]\n",
    "def prepare(df, volume_max=None):  \n",
    "    if not volume_max:\n",
    "        df = df.join(df.groupby(\"ticker\").volume.max(), on = \"ticker\", rsuffix=\"_max\")\n",
    "        df.volume = df.volume / df.volume_max\n",
    "    else:\n",
    "        df.volume = df.volume / volume_max\n",
    "    df[cols] = df[cols].astype(np.float32)\n",
    "    df = df.groupby(\"date\")[cols].apply(lambda x: pd.Series({\"x\": np.array(x)}))[\"x\"].reset_index()\n",
    "    return df, volume_max\n",
    "\n",
    "df_train, volume_max = prepare(df_train, volume_max=None)\n",
    "df_test, _ = prepare(df_test, volume_max=volume_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f31073",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack(df[\"x\"].values)\n",
    "for i in range(1):\n",
    "    plt.plot(x[:,48,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25419fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 5\n",
    "def get_data_generator(df, n_days, batch_size=0, training=True):\n",
    "    n  = 0\n",
    "    n_tickers = 130\n",
    "    while True:\n",
    "        n += 1\n",
    "        logging.info(f\"Restarting data for the {n}th time.\")\n",
    "        tot_days = df.shape[0]\n",
    "        # Real number is batch_size - 2, to be investigate why.\n",
    "        i_list = list(range(n_days + batch_size, tot_days - batch_size))\n",
    "        if training:\n",
    "            np.random.shuffle(i_list)\n",
    "        for i in range(batch_size, len(i_list) - batch_size, batch_size):\n",
    "            X = []\n",
    "            Y = []\n",
    "            for j in range(batch_size):\n",
    "                idx = i_list[i + j]\n",
    "                for_zero_division = np.concatenate([np.zeros((1, n_tickers, 5)), np.ones((1, n_tickers, 1))], axis = 2)\n",
    "                norm = (np.array([df.iloc[idx-1][\"x\"]]) + for_zero_division)\n",
    "                x = np.array([np.stack(df.iloc[idx-n_days:idx][\"x\"].values)]) / norm\n",
    "                y = (np.array([df.iloc[idx][\"x\"]]) / norm)[:,:,:4]\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            X = np.vstack(X)\n",
    "            Y = np.vstack(Y)\n",
    "            yield X, Y\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "train_tot_days = df_train.shape[0]\n",
    "train_gen = get_data_generator(df_train, n_days, batch_size=batch_size)\n",
    "train_nb_steps = len([i for i in range(batch_size, len(list(range(n_days + batch_size, train_tot_days - batch_size))) - batch_size, batch_size)])\n",
    "test_tot_days = df_test.shape[0]\n",
    "test_gen = get_data_generator(df_test, n_days, batch_size=batch_size, training=False)\n",
    "test_nb_steps = len([i for i in range(batch_size, len(list(range(n_days + batch_size, test_tot_days - batch_size))) - batch_size, batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e6a4109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 1th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014\n"
     ]
    }
   ],
   "source": [
    "def mse(y_pred, y_true):\n",
    "    return round(np.sum((y_pred - y_true)**2) / np.prod([i for i in y_pred.shape]), 4)\n",
    "test_tot_days = df_test.shape[0]\n",
    "test_gen = get_data_generator(df_test, n_days, batch_size=batch_size, training=False)\n",
    "test_nb_steps = len([i for i in range(batch_size, len(list(range(n_days + batch_size, test_tot_days - batch_size))) - batch_size, batch_size)])\n",
    "x_test, y_test = list(zip(*[next(test_gen) for i in range(test_nb_steps)]))\n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)\n",
    "print(\"Test loss baseline:\" mse(x_test[:,-1,:,:4],y_test))\n",
    "\n",
    "train_tot_days = df_train.shape[0]\n",
    "train_gen = get_data_generator(df_train, n_days, batch_size=batch_size)\n",
    "train_nb_steps = len([i for i in range(batch_size, len(list(range(n_days + batch_size, train_tot_days - batch_size))) - batch_size, batch_size)])\n",
    "x_test, y_test = list(zip(*[next(train_gen) for i in range(train_nb_steps)]))\n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)\n",
    "print(\"Test loss baseline:\" mse(x_test[:,-1,:,:4],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7922bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 5, 130, 6)]       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 3, 130, 12)        444       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 130, 10)        730       \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 1, 130, 8)         248       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 130, 6)         150       \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 1, 130, 4)         76        \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 520)               0         \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 130, 4)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,648\n",
      "Trainable params: 1,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "682/688 [============================>.] - ETA: 0s - loss: 0.0185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 3th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0184"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 32th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 9s 11ms/step - loss: 0.0184 - val_loss: 0.0045\n",
      "Epoch 2/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 4th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 33th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 11ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 3/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 5th time.\n",
      "INFO:root:Restarting data for the 34th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 4/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 6th time.\n",
      "INFO:root:Restarting data for the 35th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 5/1000\n",
      "682/688 [============================>.] - ETA: 0s - loss: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 7th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 36th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 6/1000\n",
      "682/688 [============================>.] - ETA: 0s - loss: 0.0020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 8th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "687/688 [============================>.] - ETA: 0s - loss: 0.0020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 37th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 8s 11ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 7/1000\n",
      "683/688 [============================>.] - ETA: 0s - loss: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 9th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 38th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 8/1000\n",
      "686/688 [============================>.] - ETA: 0s - loss: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 10th time.\n",
      "INFO:root:Restarting data for the 39th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 9/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 11th time.\n",
      "INFO:root:Restarting data for the 40th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 10/1000\n",
      "682/688 [============================>.] - ETA: 0s - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 12th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 41th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 11/1000\n",
      "686/688 [============================>.] - ETA: 0s - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 13th time.\n",
      "INFO:root:Restarting data for the 42th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 12/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 14th time.\n",
      "INFO:root:Restarting data for the 43th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 13/1000\n",
      "686/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 15th time.\n",
      "INFO:root:Restarting data for the 44th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/1000\n",
      "685/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 16th time.\n",
      "INFO:root:Restarting data for the 45th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 15/1000\n",
      "683/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 17th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 46th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 8s 11ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 16/1000\n",
      "685/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 18th time.\n",
      "INFO:root:Restarting data for the 47th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 11ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 17/1000\n",
      "683/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 19th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 48th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 11ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 18/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 20th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 49th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 21th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 50th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 7s 10ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/1000\n",
      "685/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 22th time.\n",
      "INFO:root:Restarting data for the 51th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 9s 13ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 21/1000\n",
      "683/688 [============================>.] - ETA: 0s - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 23th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 52th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 10s 15ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "682/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 24th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "687/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 53th time.\n",
      "INFO:root:Restarting data for the 54th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 11s 15ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/1000\n",
      "686/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 25th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 55th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 9s 13ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/1000\n",
      "682/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 26th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 56th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 9s 13ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 25/1000\n",
      "685/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 27th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "688/688 [==============================] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 57th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 8s 11ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 26/1000\n",
      "684/688 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Restarting data for the 28th time.\n",
      "INFO:root:Restarting data for the 58th time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 9s 14ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 27/1000\n",
      " 78/688 [==>...........................] - ETA: 7s - loss: 0.0020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model()\n\u001b[1;32m---> 24\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_nb_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_nb_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfl\n",
    "def get_model():\n",
    "    n_tickers = 130\n",
    "    input_shape = (n_days, n_tickers, len(cols),)\n",
    "    output_shape = (n_tickers, 4)\n",
    "    inp = tfl.Input(input_shape)\n",
    "    conv = tfl.Conv2D(filters=12, kernel_size=(2,3), strides=(2, 1), padding=\"same\", activation = None)(inp)\n",
    "    conv = tfl.Conv2D(filters=10, kernel_size=(2,3), strides=(2, 1), padding=\"same\", activation = None)(conv)\n",
    "    conv = tfl.Conv2D(filters=8, kernel_size=(1,3), strides=(2, 1), padding=\"same\", activation = None)(conv)\n",
    "    conv = tfl.Conv2D(filters=6, kernel_size=(1,3), strides=(2, 1), padding=\"same\", activation = None)(conv)\n",
    "    conv = tfl.Conv2D(filters=4, kernel_size=(1,3), strides=(2, 1), padding=\"same\", activation = None)(conv)\n",
    "    #conv = tfl.Add()([conv, inp[:,-1,:,:4]])\n",
    "    dense = tfl.Flatten()(conv)\n",
    "#     dense = tfl.Dense(596)(dense)\n",
    "#     dense = tfl.Add()([dense, (tfl.Flatten()(inp[:,-1,:,:4]))])\n",
    "    output = tfl.Reshape(output_shape)(dense)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "h = model.fit(train_gen, validation_data=test_gen, epochs=1000, steps_per_epoch=train_nb_steps, validation_steps=test_nb_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history[\"loss\"][4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed73309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred, y_true):\n",
    "    return round(np.sum((y_pred - y_true)**2) / np.prod([i for i in y_pred.shape]), 4)\n",
    "gen = get_data_generator(df, n_days, batch_size=batch_size)\n",
    "nb_steps = len([i for i in range(batch_size, len(list(range(n_days + batch_size, tot_days - batch_size))) - batch_size, batch_size)])\n",
    "x_test, y_test = list(zip(*[next(gen) for i in range(nb_steps)]))\n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)\n",
    "y_pred = model.predict(x_test)\n",
    "print(mse(y_pred, y_test), mse(x_test[:,-1,:,:4],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(np.mean(((y_pred - y_test)**2), axis = 0)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71bd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_data_generator(df, n_days, batch_size=batch_size)\n",
    "nb_steps = len([i for i in range(batch_size, len(list(range(n_days + batch_size, tot_days - batch_size))) - batch_size, batch_size)])\n",
    "x_test, y_test = list(zip(*[next(gen) for i in range(nb_steps)]))\n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)\n",
    "mse(x_test[:,-1,:,:4],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = list(zip(*[next(gen) for i in range(10)]))\n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)\n",
    "y_pred = model.predict(x_test)\n",
    "list(zip(y_pred, y_test))\n",
    "model.evaluate(x_test, y_test)\n",
    "print(mse(y_pred, y_test), mse(x_test[:,-1,:,:4],y_test))\n",
    "plt.plot(np.concatenate([x_test[0,:,68,0], y_test[0,0,0:1]]), c=\"g\")\n",
    "plt.plot(np.concatenate([x_test[0,:,68,0], y_pred[0,0,0:1]]), c=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a2ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d34f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_id = np.random.randint(0, 205)\n",
    "sample_id = 91\n",
    "plt.plot(np.concatenate([x_test[sample_id,:,ticker_id,0], y_test[sample_id,ticker_id,0:1]]), c=\"g\")\n",
    "plt.plot(np.concatenate([x_test[sample_id,:,ticker_id,0], y_pred[sample_id,ticker_id,0:1]]), c=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([mse(y_pred[91, i], y_test[91, i]) for i in range(205)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_id = np.random.randint(0, 205)\n",
    "plt.plot(np.concatenate([x_test[91,:,ticker_id,0], y_test[91,ticker_id,0:1]]), c=\"g\")\n",
    "plt.plot(np.concatenate([x_test[91,:,ticker_id,0], y_pred[91,ticker_id,0:1]]), c=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
